name: 'Terraform Destroy (Multi Cloud) and Summary'
description: 'Destroys Terraform-managed infrastructure and displays a summary in the GitHub Step Summary.'

inputs:
  # Cloud Provider Selection
  cloud-provider:
    description: "Target cloud provider or platform (aws, gcp, azure, snowflake, databricks, platform)"
    required: true
    type: string
  tf-config-path:
    description: "Relative path from the repository root to the Terraform configuration directory. This is where your main.tf, variables.tf, and other Terraform files are located."
    required: false
    type: string
    default: "tf"
  release-tag:
    description: "Git release tag to check out. If omitted, the latest commit on the default branch is used."
    required: false
    type: string
    default: ""
  ci-pipeline:
    description: "Set to 'true' to include the commit SHA in the Terraform state key (suitable for CI/CD). Use 'false' for static state keys."
    required: false
    type: string
    default: "false"

  # Backend Type Selection
  backend-type:
    description: "Backend type to use: 's3' for AWS S3 or 'remote' for HCP Terraform Cloud."
    required: false
    type: string
    default: "s3"

  # AWS S3 Backend Configuration
  s3-bucket:
    description: "Name of the S3 bucket used as the backend for storing the Terraform state file (AWS only)."
    required: false
    type: string

  s3-region:
    description: "AWS region where the S3 backend bucket is located (e.g., us-east-1, eu-west-1) (AWS only)."
    required: false
    type: string

  s3-key-prefix:
    description: "Optional prefix for the S3 state key (AWS only)."
    required: false
    type: string
    default: ""

  # HCP Terraform Cloud Inputs
  tfc-token:
    description: "HCP Terraform Cloud API token. Should be passed as a secret. Required when backend-type is 'remote'."
    required: false
    type: string

  # AWS Authentication Inputs
  aws-region:
    description: "AWS region for authentication. Required when cloud-provider is 'aws'."
    required: false
    type: string

  aws-role-to-assume:
    description: "AWS IAM role ARN to assume. Required when cloud-provider is 'aws'."
    required: false
    type: string

  # GCP Authentication Inputs
  gcp-wif-provider:
    description: "GCP Workload Identity Federation provider. Required when cloud-provider is 'gcp'."
    required: false
    type: string

  gcp-service-account:
    description: "GCP service account email for authentication. Required when cloud-provider is 'gcp'."
    required: false
    type: string

  # Azure Authentication Inputs
  azure-client-id:
    description: "Azure client ID for authentication. Required when cloud-provider is 'azure'."
    required: false
    type: string

  azure-tenant-id:
    description: "Azure tenant ID for authentication. Required when cloud-provider is 'azure'."
    required: false
    type: string

  azure-subscription-id:
    description: "Azure subscription ID for authentication. Required when cloud-provider is 'azure'."
    required: false
    type: string

runs:
  using: 'composite'
  steps:

    # ðŸ“‹ Correct Step Sequence:
    ################################################
    # Debug - Print All Inputs - Debug information
    # Validate Configuration - Input validation
    # Set Checkout Ref - Determine checkout reference
    # Checkout Repo - Get the code
    # Setup Terraform - Install Terraform
    # Configure Cloud Authentication - OIDC authentication (AWS/Azure/GCP)
    # Note: Snowflake/Databricks auth should be set via env vars in caller workflow
    # Setup TFC Credentials - HCP Terraform Cloud credentials (if remote)
    # Initialize Remote Backend - HCP Terraform Cloud init (if remote)
    # Generate State Key - Create S3 state key (if S3)
    # Initialize S3 Backend - S3 backend init (if S3)
    # Terraform Destroy with Summary - Execute the terraform destroy

    # Print all inputs for debug
    #############################################
    - name: Debug - Print All Inputs
      id: debug-inputs
      shell: bash
      run: |
        echo "=== DEBUG: All Action Inputs ==="
        echo "backend-type: ${{ inputs.backend-type }}"
        echo "cloud-provider: ${{ inputs.cloud-provider }}"
        echo "tf-config-path: ${{ inputs.tf-config-path}}"
        echo "release-tag: ${{ inputs.release-tag }}"
        echo "ci-pipeline: ${{ inputs.ci-pipeline }}"
        echo ""
        echo "=== AWS S3 Backend Inputs ==="
        echo "s3-bucket: ${{ inputs.s3-bucket }}"
        echo "s3-region: ${{ inputs.s3-region }}"
        echo "s3-key-prefix: ${{ inputs.s3-key-prefix }}"
        echo ""
        echo "=== HCP Terraform Cloud Inputs ==="
        echo "tfc-token: [REDACTED - $(if [[ -n '${{ inputs.tfc-token }}' ]]; then echo 'PROVIDED'; else echo 'NOT PROVIDED'; fi)]"
        echo ""
        echo "=== AWS Authentication Inputs ==="
        echo "aws-region: ${{ inputs.aws-region }}"
        echo "aws-role-to-assume: ${{ inputs.aws-role-to-assume }}"
        echo ""
        echo "=== GCP Authentication Inputs ==="
        echo "gcp-wif-provider: ${{ inputs.gcp-wif-provider }}"
        echo "gcp-service-account: ${{ inputs.gcp-service-account }}"
        echo ""
        echo "=== Azure Authentication Inputs ==="
        echo "azure-client-id: ${{ inputs.azure-client-id }}"
        echo "azure-tenant-id: ${{ inputs.azure-tenant-id }}"
        echo "azure-subscription-id: ${{ inputs.azure-subscription-id }}"
        echo ""
        echo "=== Snowflake/Databricks Authentication ==="
        echo "Note: Snowflake and Databricks authentication should be configured"
        echo "      via environment variables in the caller workflow."
        echo "================================="

    # Validate input configuration
    #############################################
    - name: Validate Input Configuration
      id: validate-config
      shell: bash
      run: |
        # Validate backend-type input
        if [[ "${{ inputs.backend-type }}" != "s3" && "${{ inputs.backend-type }}" != "remote" ]]; then
          echo "Error: Invalid backend-type '${{ inputs.backend-type }}'. Must be either 's3' or 'remote'"
          exit 1
        fi
        echo "âœ… Valid backend-type: ${{ inputs.backend-type }}"

        # Validate cloud-provider input
        if [[ "${{ inputs.cloud-provider }}" != "aws" && "${{ inputs.cloud-provider }}" != "gcp" && "${{ inputs.cloud-provider }}" != "azure" && "${{ inputs.cloud-provider }}" != "snowflake" && "${{ inputs.cloud-provider }}" != "databricks" && "${{ inputs.cloud-provider }}" != "platform" ]]; then
          echo "Error: Invalid cloud-provider '${{ inputs.cloud-provider }}'. Must be one of: aws, gcp, azure, snowflake, databricks, platform"
          exit 1
        fi
        echo "âœ… Valid cloud-provider: ${{ inputs.cloud-provider }}"

        # Validate backend configuration
        if [[ "${{ inputs.backend-type }}" == "s3" ]]; then
          if [[ -z "${{ inputs.s3-bucket }}" || -z "${{ inputs.s3-region }}" ]]; then
            echo "Error: s3-bucket and s3-region are required when backend-type is 's3'"
            exit 1
          fi
        elif [[ "${{ inputs.backend-type }}" == "remote" ]]; then
          if [[ -z "${{ inputs.tfc-token }}" ]]; then
            echo "Error: tfc-token is required when backend-type is 'remote'"
            exit 1
          fi
          echo "Using existing backend configuration from Terraform files"
        fi

        # Validate cloud provider configuration
        case "${{ inputs.cloud-provider }}" in
          "aws")
            if [[ -z "${{ inputs.aws-region }}" || -z "${{ inputs.aws-role-to-assume }}" ]]; then
              echo "Error: aws-region and aws-role-to-assume are required when cloud-provider is 'aws'"
              exit 1
            fi
            ;;
          "gcp")
            if [[ -z "${{ inputs.gcp-wif-provider }}" || -z "${{ inputs.gcp-service-account }}" ]]; then
              echo "Error: gcp-wif-provider and gcp-service-account are required when cloud-provider is 'gcp'"
              exit 1
            fi
            ;;
          "azure")
            if [[ -z "${{ inputs.azure-client-id }}" || -z "${{ inputs.azure-tenant-id }}" || -z "${{ inputs.azure-subscription-id }}" ]]; then
              echo "Error: azure-client-id, azure-tenant-id, and azure-subscription-id are required when cloud-provider is 'azure'"
              exit 1
            fi
            ;;
          "snowflake")
            echo "Snowflake mode: Authentication should be configured via environment variables in the caller workflow."
            echo "Required environment variables: SNOWFLAKE_ACCOUNT, SNOWFLAKE_USER, SNOWFLAKE_ROLE, SNOWFLAKE_PRIVATE_KEY_PATH"
            ;;
          "databricks")
            echo "Databricks mode: Authentication should be configured via environment variables in the caller workflow."
            echo "Required environment variables: DATABRICKS_HOST, DATABRICKS_TOKEN"
            ;;
          "platform")
            echo "Platform mode: Checking for cloud provider directories in infra/"
            VALIDATION_ERRORS=""

            # Check for AWS directory
            if [[ -d "infra/aws" ]]; then
              echo "Found infra/aws directory - validating AWS inputs..."
              if [[ -z "${{ inputs.aws-region }}" || -z "${{ inputs.aws-role-to-assume }}" ]]; then
                VALIDATION_ERRORS="${VALIDATION_ERRORS}\n- AWS: aws-region and aws-role-to-assume are required"
              else
                echo "  âœ… AWS inputs validated"
              fi
            fi

            # Check for GCP directory
            if [[ -d "infra/gcp" ]]; then
              echo "Found infra/gcp directory - validating GCP inputs..."
              if [[ -z "${{ inputs.gcp-wif-provider }}" || -z "${{ inputs.gcp-service-account }}" ]]; then
                VALIDATION_ERRORS="${VALIDATION_ERRORS}\n- GCP: gcp-wif-provider and gcp-service-account are required"
              else
                echo "  âœ… GCP inputs validated"
              fi
            fi

            # Check for Azure directory
            if [[ -d "infra/azure" ]]; then
              echo "Found infra/azure directory - validating Azure inputs..."
              if [[ -z "${{ inputs.azure-client-id }}" || -z "${{ inputs.azure-tenant-id }}" || -z "${{ inputs.azure-subscription-id }}" ]]; then
                VALIDATION_ERRORS="${VALIDATION_ERRORS}\n- Azure: azure-client-id, azure-tenant-id, and azure-subscription-id are required"
              else
                echo "  âœ… Azure inputs validated"
              fi
            fi

            # Check for Snowflake directory
            if [[ -d "infra/snowflake" ]]; then
              echo "Found infra/snowflake directory - Snowflake authentication should be configured via environment variables in the caller workflow."
            fi

            # Check for Databricks directory
            if [[ -d "infra/databricks" ]]; then
              echo "Found infra/databricks directory - Databricks authentication should be configured via environment variables in the caller workflow."
            fi

            # Check if any validation errors occurred
            if [[ -n "$VALIDATION_ERRORS" ]]; then
              echo ""
              echo "Error: Missing required inputs for detected platforms:"
              echo -e "$VALIDATION_ERRORS"
              exit 1
            fi
            echo "All detected platform inputs validated successfully"
            ;;
        esac

    # Determine checkout reference
    #############################################
    - name: Set Checkout Ref
      id: set-ref
      shell: bash
      run: |
        if [[ -n "${{ inputs.release-tag }}" ]]; then
          echo "ref=${{ inputs.release-tag }}" >> $GITHUB_OUTPUT
        else
          echo "ref=${GITHUB_REF_NAME}" >> $GITHUB_OUTPUT
        fi

    # Checkout repo and setup Terraform
    #############################################
    - name: Checkout Repo
      id: checkout
      uses: actions/checkout@v6
      with:
        ref: ${{ steps.set-ref.outputs.ref }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3

    #  Cloud Provider Authentication (OIDC)
    #############################################
    - name: Configure AWS Authentication
      if: inputs.cloud-provider == 'aws' || inputs.backend-type == 's3' || (inputs.aws-role-to-assume != '' && inputs.aws-region != '')
      uses: aws-actions/configure-aws-credentials@v5
      with:
        aws-region: ${{ inputs.aws-region }}
        role-to-assume: ${{ inputs.aws-role-to-assume }}

    - name: Configure Azure Authentication
      if: (inputs.cloud-provider == 'azure') || (inputs.cloud-provider == 'platform' && inputs.azure-client-id != '' && inputs.azure-tenant-id != '' && inputs.azure-subscription-id != '')
      uses: azure/login@v2
      with:
        client-id: ${{ inputs.azure-client-id }}
        tenant-id: ${{ inputs.azure-tenant-id }}
        subscription-id: ${{ inputs.azure-subscription-id }}

    - name: Configure GCP Authentication (WIF)
      if: (inputs.cloud-provider == 'gcp') || (inputs.cloud-provider == 'platform' && inputs.gcp-wif-provider != '' && inputs.gcp-service-account != '')
      uses: google-github-actions/auth@v3
      with:
        workload_identity_provider: ${{ inputs.gcp-wif-provider }}
        service_account: ${{ inputs.gcp-service-account }}

    #  Terraform Cloud Backend 
    #############################################
    - name: Setup Terraform Cloud Credentials
      id: setup-tfc-credentials
      if: inputs.backend-type == 'remote'
      shell: bash
      run: |
        mkdir -p ~/.terraform.d
        cat > ~/.terraform.d/credentials.tfrc.json << EOF
        {
          "credentials": {
            "app.terraform.io": {
              "token": "${{ inputs.tfc-token }}"
            }
          }
        }
        EOF

    - name: Initialize Terraform with HCP Terraform Cloud Backend
      id: terraform-init-remote
      if: inputs.backend-type == 'remote'
      shell: bash
      working-directory: ${{ github.workspace }}/${{ inputs.tf-config-path }}
      run: |
        terraform init -input=false

    #  AWS S3 Backend 
    #############################################
    - name: Generate Terraform State Key
      id: generate-tfstate-key
      if: inputs.backend-type == 's3'
      shell: bash
      working-directory: ${{ github.workspace }}/${{ inputs.tf-config-path }}
      run: |
        if [[ "${{ inputs.ci-pipeline }}" == "true" ]]; then
          state_key="${{ github.repository }}/${{ github.sha }}/terraform.tfstate"
        else
          state_key="${{ github.repository }}/terraform.tfstate"
        fi
        echo "state_key=$state_key" >> $GITHUB_OUTPUT

    - name: Initialize Terraform with S3 Backend
      id: terraform-init-s3
      if: inputs.backend-type == 's3'
      shell: bash
      working-directory: ${{ github.workspace }}/${{ inputs.tf-config-path }}
      run: |
        # Build state key with optional prefix
        if [[ -n "${{ inputs.s3-key-prefix }}" ]]; then
          full_key="${{ inputs.s3-key-prefix }}/${{ steps.generate-tfstate-key.outputs.state_key }}"
        else
          full_key="${{ steps.generate-tfstate-key.outputs.state_key }}"
        fi

        # Initialize with S3 backend
        terraform init -input=false \
          -backend-config="bucket=${{ inputs.s3-bucket }}" \
          -backend-config="key=$full_key" \
          -backend-config="region=${{ inputs.s3-region }}" \
          -backend-config="encrypt=true" \
          -backend-config="use_lockfile=true"

    # Final step - Terraform destroy
    #############################################
    - name: Terraform Destroy
      id: tf-destroy
      shell: bash
      working-directory: ${{ github.workspace }}/${{ inputs.tf-config-path }}
      run: |
        START_TIME=$(date -u "+%Y-%m-%d %H:%M:%S UTC")

        echo "## â˜ ï¸ Terraform Destroy Output" >> "$GITHUB_STEP_SUMMARY"
        echo "_**Started at: ${START_TIME}**_" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"

        # Generate destroy plan and JSON view
        terraform plan -destroy -out=tfplan-destroy.out -input=false
        terraform show -json tfplan-destroy.out > tfplan-destroy.json

        echo "---------------------"
        cat tfplan-destroy.json
        echo "---------------------"

        # Perform the actual destroy
        terraform destroy -auto-approve -input=false | tee destroy_output.txt || exit 1

        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "### Resources Destroyed" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "| Resource Type | Resource Name     | Address                          | Timestamp               |" >> "$GITHUB_STEP_SUMMARY"
        echo "|---------------|--------------------|----------------------------------|--------------------------|" >> "$GITHUB_STEP_SUMMARY"

        jq -r --arg timestamp "$START_TIME" '
          .resource_changes[]
          | select(.change.actions == ["delete"])
          | [
              (.type // "-"),
              (.name // "-"),
              (.address // "-"),
              $timestamp
            ]
          | @tsv
        ' tfplan-destroy.json | while IFS=$'\t' read -r type name address timestamp; do
          echo "| $type | $name | $address | $timestamp |" >> "$GITHUB_STEP_SUMMARY"
        done

        echo "" >> "$GITHUB_STEP_SUMMARY"
        END_TIME=$(date -u "+%Y-%m-%d %H:%M:%S UTC")
        echo "_**Completed at: ${END_TIME}**_" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"

